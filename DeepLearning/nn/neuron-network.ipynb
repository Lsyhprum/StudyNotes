{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36264bit36fc170516d04460ae12d1efa3e0666b",
   "display_name": "Python 3.6.2 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10000, 3072)\n(2000, 3072)\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "CIFAR_DIR = '..\\\\cifar-10-batches-py'\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(os.path.join(CIFAR_DIR, filename), 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "        return data[b'data'], data[b'labels']\n",
    "    \n",
    "class Cifar_data:\n",
    "    def __init__(self, filenames, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "\n",
    "        for filename in filenames:\n",
    "            data, labels = load_data(filename)\n",
    "            for d, l in zip(data, labels):\n",
    "                if l in [0, 1]:\n",
    "                    all_data.append(d)\n",
    "                    all_labels.append(l)\n",
    "    \n",
    "        self._data = np.vstack(all_data)                # 0.4865\n",
    "        self._data = self._data / 127.5 - 1              \n",
    "        self._labels = np.hstack(all_labels)\n",
    "        print(self._data.shape)\n",
    "\n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "    \n",
    "    def _shuffle_data(self):\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"return batch_size examples as a batch\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:          \n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is lager than all example\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "train_filenames = [os.path.join(CIFAR_DIR, \"data_batch_%d\" % i) for i in range(1, 6)]\n",
    "test_filename = [os.path.join(CIFAR_DIR, \"test_batch\")]\n",
    "\n",
    "train_data = Cifar_data(train_filenames, True)\n",
    "test_data = Cifar_data(test_filename, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 3072])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "w = tf.get_variable('w', [x.get_shape()[-1], 1], initializer=tf.random_normal_initializer(0, 1))\n",
    "b = tf.get_variable('b', [1], initializer=tf.constant_initializer(0.0))          # 错误 random_normal_initializer\n",
    "\n",
    "y_ = tf.matmul(x, w) + b\n",
    "p_y_ = tf.sigmoid(y_)            # ？？\n",
    "\n",
    "y_reshape = tf.reshape(y, (-1, 1))\n",
    "y_reshape_float = tf.cast(y_reshape, tf.float32)\n",
    "loss = tf.reduce_mean(tf.square(y_reshape_float - p_y_))\n",
    "\n",
    "predict = p_y_ > 0.5\n",
    "correct_predict = tf.equal(tf.cast(predict, tf.int64), y_reshape)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float64))\n",
    "\n",
    "with tf.name_scope('train_scope'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "merged_summary_test = tf.summary.merge([loss_summary, accuracy_summary])\n",
    "\n",
    "LOG_DIR = '.'\n",
    "run_label = 'run_nn_tensorboard'\n",
    "run_dir = os.path.join(LOG_DIR, run_label)\n",
    "\n",
    "if not os.path.exists(run_dir):\n",
    "    os.mkdir(run_dir)\n",
    "\n",
    "train_log_dir = os.path.join(run_dir, 'train')\n",
    "test_log_dir = os.path.join(run_dir, 'test')\n",
    "if not os.path.exists(train_log_dir):\n",
    "    os.mkdir(train_log_dir)\n",
    "if not os.path.exists(test_log_dir):\n",
    "    os.mkdir(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[Train] Step：500, loss: 0.21369, acc: 0.75000\n[Train] Step：1000, loss: 0.24979, acc: 0.75000\n[Train] Step：1500, loss: 0.15247, acc: 0.85000\n[Train] Step：2000, loss: 0.33463, acc: 0.65000\n[Train] Step：2500, loss: 0.34952, acc: 0.65000\n[Train] Step：3000, loss: 0.22325, acc: 0.75000\n[Train] Step：3500, loss: 0.29974, acc: 0.70000\n[Train] Step：4000, loss: 0.05043, acc: 0.95000\n[Train] Step：4500, loss: 0.34859, acc: 0.65000\n[Train] Step：5000, loss: 0.12762, acc: 0.85000\n(2000, 3072)\n[Test] Step: 5000, acc: 0.81300\n[Train] Step：5500, loss: 0.19653, acc: 0.80000\n[Train] Step：6000, loss: 0.21092, acc: 0.75000\n[Train] Step：6500, loss: 0.10000, acc: 0.90000\n[Train] Step：7000, loss: 0.15000, acc: 0.85000\n[Train] Step：7500, loss: 0.05000, acc: 0.95000\n[Train] Step：8000, loss: 0.15000, acc: 0.85000\n[Train] Step：8500, loss: 0.25022, acc: 0.75000\n[Train] Step：9000, loss: 0.15544, acc: 0.85000\n[Train] Step：9500, loss: 0.20001, acc: 0.80000\n[Train] Step：10000, loss: 0.25006, acc: 0.75000\n(2000, 3072)\n[Test] Step: 10000, acc: 0.81950\n[Train] Step：10500, loss: 0.09998, acc: 0.90000\n[Train] Step：11000, loss: 0.19152, acc: 0.80000\n[Train] Step：11500, loss: 0.30190, acc: 0.70000\n[Train] Step：12000, loss: 0.15000, acc: 0.85000\n[Train] Step：12500, loss: 0.25619, acc: 0.75000\n[Train] Step：13000, loss: 0.15000, acc: 0.85000\n[Train] Step：13500, loss: 0.29990, acc: 0.70000\n[Train] Step：14000, loss: 0.19997, acc: 0.80000\n[Train] Step：14500, loss: 0.19995, acc: 0.80000\n[Train] Step：15000, loss: 0.19976, acc: 0.80000\n(2000, 3072)\n[Test] Step: 15000, acc: 0.82000\n[Train] Step：15500, loss: 0.07935, acc: 0.90000\n[Train] Step：16000, loss: 0.20018, acc: 0.80000\n[Train] Step：16500, loss: 0.15231, acc: 0.85000\n[Train] Step：17000, loss: 0.10103, acc: 0.90000\n[Train] Step：17500, loss: 0.27969, acc: 0.70000\n[Train] Step：18000, loss: 0.12617, acc: 0.85000\n[Train] Step：18500, loss: 0.15716, acc: 0.85000\n[Train] Step：19000, loss: 0.13956, acc: 0.85000\n[Train] Step：19500, loss: 0.35000, acc: 0.65000\n[Train] Step：20000, loss: 0.23240, acc: 0.75000\n(2000, 3072)\n[Test] Step: 20000, acc: 0.81750\n[Train] Step：20500, loss: 0.22421, acc: 0.75000\n[Train] Step：21000, loss: 0.11038, acc: 0.85000\n[Train] Step：21500, loss: 0.25000, acc: 0.75000\n[Train] Step：22000, loss: 0.20000, acc: 0.80000\n[Train] Step：22500, loss: 0.19700, acc: 0.80000\n[Train] Step：23000, loss: 0.10006, acc: 0.90000\n[Train] Step：23500, loss: 0.20003, acc: 0.80000\n[Train] Step：24000, loss: 0.21924, acc: 0.75000\n[Train] Step：24500, loss: 0.15077, acc: 0.85000\n[Train] Step：25000, loss: 0.05616, acc: 0.95000\n(2000, 3072)\n[Test] Step: 25000, acc: 0.81500\n[Train] Step：25500, loss: 0.04898, acc: 0.95000\n[Train] Step：26000, loss: 0.15112, acc: 0.85000\n[Train] Step：26500, loss: 0.25367, acc: 0.75000\n[Train] Step：27000, loss: 0.05000, acc: 0.95000\n[Train] Step：27500, loss: 0.10112, acc: 0.90000\n[Train] Step：28000, loss: 0.15858, acc: 0.85000\n[Train] Step：28500, loss: 0.10000, acc: 0.90000\n[Train] Step：29000, loss: 0.25024, acc: 0.75000\n[Train] Step：29500, loss: 0.29984, acc: 0.70000\n[Train] Step：30000, loss: 0.05134, acc: 0.95000\n(2000, 3072)\n[Test] Step: 30000, acc: 0.81900\n[Train] Step：30500, loss: 0.25346, acc: 0.75000\n[Train] Step：31000, loss: 0.34976, acc: 0.65000\n[Train] Step：31500, loss: 0.05000, acc: 0.95000\n[Train] Step：32000, loss: 0.10000, acc: 0.90000\n[Train] Step：32500, loss: 0.23465, acc: 0.70000\n[Train] Step：33000, loss: 0.12206, acc: 0.85000\n[Train] Step：33500, loss: 0.15304, acc: 0.85000\n[Train] Step：34000, loss: 0.05000, acc: 0.95000\n[Train] Step：34500, loss: 0.10000, acc: 0.90000\n[Train] Step：35000, loss: 0.08134, acc: 0.90000\n(2000, 3072)\n[Test] Step: 35000, acc: 0.82150\n[Train] Step：35500, loss: 0.20473, acc: 0.80000\n[Train] Step：36000, loss: 0.15421, acc: 0.85000\n[Train] Step：36500, loss: 0.07699, acc: 0.90000\n[Train] Step：37000, loss: 0.11054, acc: 0.85000\n[Train] Step：37500, loss: 0.20098, acc: 0.80000\n[Train] Step：38000, loss: 0.15051, acc: 0.85000\n[Train] Step：38500, loss: 0.00422, acc: 1.00000\n[Train] Step：39000, loss: 0.05002, acc: 0.95000\n[Train] Step：39500, loss: 0.10265, acc: 0.90000\n[Train] Step：40000, loss: 0.15172, acc: 0.85000\n(2000, 3072)\n[Test] Step: 40000, acc: 0.82050\n[Train] Step：40500, loss: 0.20001, acc: 0.80000\n[Train] Step：41000, loss: 0.20001, acc: 0.80000\n[Train] Step：41500, loss: 0.05000, acc: 0.95000\n[Train] Step：42000, loss: 0.19972, acc: 0.80000\n[Train] Step：42500, loss: 0.05004, acc: 0.95000\n[Train] Step：43000, loss: 0.15162, acc: 0.85000\n[Train] Step：43500, loss: 0.09992, acc: 0.90000\n[Train] Step：44000, loss: 0.10000, acc: 0.90000\n[Train] Step：44500, loss: 0.05402, acc: 0.95000\n[Train] Step：45000, loss: 0.10002, acc: 0.90000\n(2000, 3072)\n[Test] Step: 45000, acc: 0.82100\n[Train] Step：45500, loss: 0.04664, acc: 0.95000\n[Train] Step：46000, loss: 0.25022, acc: 0.75000\n[Train] Step：46500, loss: 0.05040, acc: 0.95000\n[Train] Step：47000, loss: 0.29472, acc: 0.70000\n[Train] Step：47500, loss: 0.19270, acc: 0.80000\n[Train] Step：48000, loss: 0.00003, acc: 1.00000\n[Train] Step：48500, loss: 0.11478, acc: 0.85000\n[Train] Step：49000, loss: 0.15007, acc: 0.85000\n[Train] Step：49500, loss: 0.15000, acc: 0.85000\n[Train] Step：50000, loss: 0.20017, acc: 0.80000\n(2000, 3072)\n[Test] Step: 50000, acc: 0.82000\n[Train] Step：50500, loss: 0.05003, acc: 0.95000\n[Train] Step：51000, loss: 0.15000, acc: 0.85000\n[Train] Step：51500, loss: 0.19365, acc: 0.80000\n[Train] Step：52000, loss: 0.15003, acc: 0.85000\n[Train] Step：52500, loss: 0.10025, acc: 0.90000\n[Train] Step：53000, loss: 0.14999, acc: 0.85000\n[Train] Step：53500, loss: 0.05092, acc: 0.95000\n[Train] Step：54000, loss: 0.05005, acc: 0.95000\n[Train] Step：54500, loss: 0.12016, acc: 0.90000\n[Train] Step：55000, loss: 0.14301, acc: 0.85000\n(2000, 3072)\n[Test] Step: 55000, acc: 0.81800\n[Train] Step：55500, loss: 0.15005, acc: 0.85000\n[Train] Step：56000, loss: 0.06689, acc: 0.90000\n[Train] Step：56500, loss: 0.18510, acc: 0.80000\n[Train] Step：57000, loss: 0.29911, acc: 0.70000\n[Train] Step：57500, loss: 0.33853, acc: 0.65000\n[Train] Step：58000, loss: 0.10276, acc: 0.90000\n[Train] Step：58500, loss: 0.05000, acc: 0.95000\n[Train] Step：59000, loss: 0.20248, acc: 0.80000\n[Train] Step：59500, loss: 0.05000, acc: 0.95000\n[Train] Step：60000, loss: 0.20000, acc: 0.80000\n(2000, 3072)\n[Test] Step: 60000, acc: 0.81950\n[Train] Step：60500, loss: 0.10113, acc: 0.90000\n[Train] Step：61000, loss: 0.19967, acc: 0.80000\n[Train] Step：61500, loss: 0.10003, acc: 0.90000\n[Train] Step：62000, loss: 0.15390, acc: 0.85000\n[Train] Step：62500, loss: 0.10012, acc: 0.90000\n[Train] Step：63000, loss: 0.15000, acc: 0.85000\n[Train] Step：63500, loss: 0.15002, acc: 0.85000\n[Train] Step：64000, loss: 0.10053, acc: 0.90000\n[Train] Step：64500, loss: 0.15696, acc: 0.85000\n[Train] Step：65000, loss: 0.17264, acc: 0.80000\n(2000, 3072)\n[Test] Step: 65000, acc: 0.82250\n[Train] Step：65500, loss: 0.05646, acc: 0.95000\n[Train] Step：66000, loss: 0.10195, acc: 0.90000\n[Train] Step：66500, loss: 0.14914, acc: 0.85000\n[Train] Step：67000, loss: 0.05009, acc: 0.95000\n[Train] Step：67500, loss: 0.05552, acc: 0.95000\n[Train] Step：68000, loss: 0.15087, acc: 0.85000\n[Train] Step：68500, loss: 0.14994, acc: 0.85000\n[Train] Step：69000, loss: 0.25041, acc: 0.75000\n[Train] Step：69500, loss: 0.05306, acc: 0.95000\n[Train] Step：70000, loss: 0.11515, acc: 0.85000\n(2000, 3072)\n[Test] Step: 70000, acc: 0.82000\n[Train] Step：70500, loss: 0.30000, acc: 0.70000\n[Train] Step：71000, loss: 0.20000, acc: 0.80000\n[Train] Step：71500, loss: 0.06932, acc: 0.90000\n[Train] Step：72000, loss: 0.25453, acc: 0.75000\n[Train] Step：72500, loss: 0.10001, acc: 0.90000\n[Train] Step：73000, loss: 0.19958, acc: 0.80000\n[Train] Step：73500, loss: 0.20037, acc: 0.80000\n[Train] Step：74000, loss: 0.29999, acc: 0.70000\n[Train] Step：74500, loss: 0.15001, acc: 0.85000\n[Train] Step：75000, loss: 0.20000, acc: 0.80000\n(2000, 3072)\n[Test] Step: 75000, acc: 0.82050\n[Train] Step：75500, loss: 0.16192, acc: 0.85000\n[Train] Step：76000, loss: 0.00047, acc: 1.00000\n[Train] Step：76500, loss: 0.15006, acc: 0.85000\n[Train] Step：77000, loss: 0.25007, acc: 0.75000\n[Train] Step：77500, loss: 0.10224, acc: 0.90000\n[Train] Step：78000, loss: 0.10541, acc: 0.90000\n[Train] Step：78500, loss: 0.22363, acc: 0.75000\n[Train] Step：79000, loss: 0.10040, acc: 0.90000\n[Train] Step：79500, loss: 0.24972, acc: 0.75000\n[Train] Step：80000, loss: 0.19998, acc: 0.80000\n(2000, 3072)\n[Test] Step: 80000, acc: 0.82150\n[Train] Step：80500, loss: 0.10107, acc: 0.90000\n[Train] Step：81000, loss: 0.19834, acc: 0.80000\n[Train] Step：81500, loss: 0.15142, acc: 0.85000\n[Train] Step：82000, loss: 0.15245, acc: 0.85000\n[Train] Step：82500, loss: 0.10002, acc: 0.90000\n[Train] Step：83000, loss: 0.15348, acc: 0.85000\n[Train] Step：83500, loss: 0.05077, acc: 0.95000\n[Train] Step：84000, loss: 0.15004, acc: 0.85000\n[Train] Step：84500, loss: 0.15000, acc: 0.85000\n[Train] Step：85000, loss: 0.10131, acc: 0.90000\n(2000, 3072)\n[Test] Step: 85000, acc: 0.82150\n[Train] Step：85500, loss: 0.10000, acc: 0.90000\n[Train] Step：86000, loss: 0.10003, acc: 0.90000\n[Train] Step：86500, loss: 0.10381, acc: 0.90000\n[Train] Step：87000, loss: 0.09999, acc: 0.90000\n[Train] Step：87500, loss: 0.05014, acc: 0.95000\n[Train] Step：88000, loss: 0.20175, acc: 0.80000\n[Train] Step：88500, loss: 0.14986, acc: 0.85000\n[Train] Step：89000, loss: 0.10004, acc: 0.90000\n[Train] Step：89500, loss: 0.09998, acc: 0.90000\n[Train] Step：90000, loss: 0.05000, acc: 0.95000\n(2000, 3072)\n[Test] Step: 90000, acc: 0.82000\n[Train] Step：90500, loss: 0.25046, acc: 0.75000\n[Train] Step：91000, loss: 0.19963, acc: 0.80000\n[Train] Step：91500, loss: 0.15051, acc: 0.85000\n[Train] Step：92000, loss: 0.11472, acc: 0.85000\n[Train] Step：92500, loss: 0.05240, acc: 0.95000\n[Train] Step：93000, loss: 0.16978, acc: 0.80000\n[Train] Step：93500, loss: 0.15000, acc: 0.85000\n[Train] Step：94000, loss: 0.29986, acc: 0.70000\n[Train] Step：94500, loss: 0.05602, acc: 0.95000\n[Train] Step：95000, loss: 0.15048, acc: 0.85000\n(2000, 3072)\n[Test] Step: 95000, acc: 0.81700\n[Train] Step：95500, loss: 0.10000, acc: 0.90000\n[Train] Step：96000, loss: 0.15002, acc: 0.85000\n[Train] Step：96500, loss: 0.10808, acc: 0.90000\n[Train] Step：97000, loss: 0.20014, acc: 0.80000\n[Train] Step：97500, loss: 0.10344, acc: 0.90000\n[Train] Step：98000, loss: 0.15000, acc: 0.85000\n[Train] Step：98500, loss: 0.09999, acc: 0.90000\n[Train] Step：99000, loss: 0.15103, acc: 0.85000\n[Train] Step：99500, loss: 0.26084, acc: 0.75000\n[Train] Step：100000, loss: 0.07337, acc: 0.90000\n(2000, 3072)\n[Test] Step: 100000, acc: 0.81750\n"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 20\n",
    "train_steps = 30000\n",
    "test_steps = 100\n",
    "output_summary_every_steps = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    train_writer = tf.summary.FileWriter(train_log_dir)\n",
    "    test_writer = tf.summary.FileWriter(test_log_dir)\n",
    "\n",
    "    fixed_test_batch_data, fixed_test_batch_labels = test_data.next_batch(batch_size)\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "\n",
    "        eval_ops = [loss, accuracy, train_op]\n",
    "        should_output_summary = ((i + 1) % output_summary_every_steps == 0)\n",
    "        if should_output_summary:\n",
    "            eval_ops.append(merged_summary)\n",
    "\n",
    "        eval_ops_results = sess.run([loss, accuracy, train_op], feed_dict = {x: batch_data, y: batch_labels})\n",
    "\n",
    "        if should_output_summary:\n",
    "            train_summary_str = eval_ops_results[-1]\n",
    "            train_writer.add_summary(train_summary_str, i+1)\n",
    "            test_summary_str = sess.run([merged_summary_test], feed_dict={x: fixed_test_batch_data, y: fixed_test_batch_labels})[0]\n",
    "            test_writer.add_summary(test_summary_str, i+1)\n",
    "\n",
    "        loss_val, acc_val = eval_ops_results[0:2]\n",
    "\n",
    "        if (i+1) % 500 == 0:\n",
    "            print('[Train] Step：%d, loss: %4.5f, acc: %4.5f' % (i + 1, loss_val, acc_val))\n",
    "        if (i+1) % 5000 == 0:\n",
    "            test_data = Cifar_data(test_filename, False)\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run([accuracy], feed_dict={x:test_batch_data,y:test_batch_labels})\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.mean(all_test_acc_val)\n",
    "            print('[Test] Step: %d, acc: %4.5f' % (i+1, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}