# RNN

1 对 1
固定输入长度 cnn 图像

1 对 多

RNN 图像生成描述

多 对 1 

文本分类

多对多

机器翻译

视频解说

维护一个状态作为下一步的额外输入
每一步使用同样的激活函数和参数

反向传播

* Tanh 输出在 1 和 -1 之间

* 梯度消失

* 较远步骤梯度贡献很小

多层网络

* 低层输出作为高层输入

* 同层之间依旧递归

* 增加网络拟合能力

RNN + 残差连接

LSTM 

为什么需要 LSTM

* 普通 RNN 信息不能长久传播

* 引入选择性机制

    * 选择性输入

    * 选择性输入

    * 选择性遗忘

* 选择性 -> 门

sigmoid 函数 [0, 1]

* 遗忘门

    * 新的一句有新的主语，把之前的主语忘掉

* 传入门

    * 是不是要把主语的性别添加进来

* 输出门

    * 动词改用单数形式还是复数形式
